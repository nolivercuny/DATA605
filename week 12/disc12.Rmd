---
title: "DATA 605 - Discussion 12"
author: "Nick Oliver"
output:
  prettydoc::html_pretty:
    theme: hpstr
    highlight: github
editor_options: 
  chunk_output_type: console
---

# Discussion 12

Using R, build a multiple regression model for data that interests you.  Include in this model at least one quadratic term, one dichotomous term, and one dichotomous vs. quantitative interaction term.  Interpret all coefficients. Conduct residual analysis.  Was the linear model appropriate? Why or why not?

I am using the state of delaware's open data set. The regression model is predicting the percentage of students who are proficient on the MATH portion of the "Smarter Balanced Summative Assessment" in 2021

PctProficient: The percent of students who earned an achievement level considered proficient. This is the number of students who earned a proficient achievement level divided by the number of students who tested.

https://data.delaware.gov/Education/Student-Assessment-Performance/ms6b-mt82
```{r, echo=FALSE, message=FALSE}
library(tidyverse)
library(kableExtra)
library(performance)
library(MASS)
```
## Loading Data
```{r}
df <- read.csv('Downloads/CUNY/DATA605/data605/week\ 12/Filtered_Student_Assessment_Performance.csv')

```
## Cleanup & Aggregation

This is a very large dataset (over 700k rows) I pre-filtered it so it is easier to work with. Removed all redacted data, data for the entire state, data without race and gender information and just data for the MATH assessment. 

Dropping rows that add no extra information

```{r}
fdf <- df %>%
  mutate(NonWhite = Race != 'White') %>% 
  mutate(Male = Gender == 'Male') %>%
  mutate(GradeNum = as.numeric(gsub("([0-9]+).*$", "\\1", Grade))) %>%
  mutate(NonFosterCare = SpecialDemo == 'Non-Foster Care') %>%
  mutate(NonLowIncome = SpecialDemo == 'Non Low-Income') %>%
  mutate(LowIncome = SpecialDemo == 'Low-Income') %>%
  mutate(ActiveEL = SpecialDemo == 'Active EL Students') %>%
  mutate(NonHomeless = SpecialDemo == 'Non-Homeless') %>%
  mutate(NonELStudents = SpecialDemo == 'Non-EL Students') %>%
  mutate(Disabilities = SpecialDemo == 'Students with Disabilities') %>%
  mutate(MilitaryConnected = SpecialDemo == 'Military Connected Youth') %>%
  dplyr::select(NonWhite,Male,GradeNum,NonFosterCare,NonLowIncome,LowIncome,ActiveEL,NonHomeless,NonELStudents,Disabilities,MilitaryConnected,Tested,PctProficient)
 
glimpse(fdf)
```

## Analysis


Use built in `lm` function to fit linear model. Summary shows a `p-value` of $\approx$ 0.68 which much greater than .05 which indicates the correlation is not statistically significant. 
```{r, warning=FALSE}
model <- lm(data=fdf, PctProficient ~ NonWhite+Male+GradeNum+NonFosterCare+NonLowIncome+LowIncome+ActiveEL+NonHomeless+NonELStudents+Disabilities+MilitaryConnected+Tested)
summary(model)
```

I expeirmented with the `stepAIC` function from the `MASS` library which can do both backward and forward predictor elimination using the Akaike Information Criterion (AIC) to compare the fit of the model. Interestingly it appears to drop the NonLowIncome and MilitaryConnected predictors. 
```{r}
stepModel <- stepAIC(model, direction = 'both')
summary(stepModel)
```
Residuals plot

```{r}
 res = resid(stepModel)
plot(df$PctProficient, res,
     ylab="Residuals", xlab="% Proficient")
 abline(0, 0)                  # the horizon
ggplot(data = df, aes(x = stepModel$residuals)) +
    geom_histogram(fill = 'steelblue', color = 'black', binwidth = 1) +
    labs(title = 'Histogram of Residuals', x = 'Residuals', y = 'Frequency')
```

Shamelessly stealing the idea of using the `performance` library's `check_model` function as well.

```{r}
check_model(stepModel)
```

## Summary
Does it meet the conditions of linear regression?

**Linearity: No. Based on the point plot there really does not appear to be a linear relationship.**

**Nearly normal residuals: Yes. We can observe from the histogram plot of the residuals that their distribution sort of resembles the normal distribution**

**Constant variability: Yes. We can observe from the scatter plot of the residuals that there is no pattern present which indicates that there is constant variability**

**Independent observations: Yes. The study time and scores between individuals is independent**

Is the linear model appropriate?

**Hard to say. Doesn't seem to meet all the criteria of linear regression as I understand it. This is data from a single class of 17 students with only 3 quizzes taken so far. I think there probably just isn't enough data to draw any significant conclusions**

```{r}
cdf = read.csv('https://online.stat.psu.edu/stat462/sites/onlinecourses.science.psu.edu.stat462/files/data/poverty/index.txt', sep = '\t' )

cor(cdf[,!(names(cdf) %in% c('Brth15to17','Brth18to19','TeenBrth','Location'))], cdf$TeenBrth)
```
